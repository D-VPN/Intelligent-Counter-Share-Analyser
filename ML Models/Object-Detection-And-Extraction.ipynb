{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "artistic-arrow",
   "metadata": {},
   "source": [
    "### Using Tensorflow for object detection and extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-subject",
   "metadata": {},
   "source": [
    "#### We will implementing transfer learning with ImageAI for custom object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiovascular-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-shift",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-patrol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fuzzy-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "killing-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import xml.etree.ElementTree as xm\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, Resizing\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Flatten, Lambda, Input, Reshape\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from time import strftime\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-interstate",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baking-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf_images = \"./GroceryDataset/images/ShelfImages/\"\n",
    "product_images = \"./GroceryDataset/images/ProductImagesFromShelves/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-jordan",
   "metadata": {},
   "source": [
    "# Trying out the raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "general-specialist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.1.0.h5\"))\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unique-implement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nikhil\\\\Desktop\\\\Hackathon\\\\Intelligent-Conuter-Share-Analyzer\\\\ML Models'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "surprised-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nikhil\\\\Desktop\\\\Hackathon\\\\Intelligent-Conuter-Share-Analyzer\\\\ML Models\\\\resnet50_coco_best_v2.1.0.h5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(execution_path , \"resnet50_coco_best_v2.1.0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "reliable-bulletin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nikhil\\\\Desktop\\\\Hackathon\\\\Intelligent-Conuter-Share-Analyzer\\\\ML Models\\\\rect1.png'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(execution_path , \"rect1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worse-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottle  :  61.22475266456604\n",
      "vase  :  56.356436014175415\n"
     ]
    }
   ],
   "source": [
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"Production Assets/Shelf.jpg\"), output_image_path=os.path.join(execution_path , \"imagenew.jpg\"))\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "verified-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "\n",
    "# open_tarfile=tarfile.open(\"GroceryDataset_part1.tar.gz\")\n",
    "# open_tarfile.extractall(path='GroceryDataset_part1')\n",
    "# open_tarfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "welsh-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_tarfile=tarfile.open(\"GroceryDataset_part2.tar.gz\")\n",
    "# open_tarfile.extractall(path='GroceryDataset_part2')\n",
    "# open_tarfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-dodge",
   "metadata": {},
   "source": [
    "# Formating the data set in required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sudden-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_files = [ f for f in os.listdir(f'{shelf_images}') if f.endswith('JPG') ]\n",
    "photos_df = pd.DataFrame([[f, f[:6], f[7:14]] for f in jpg_files], columns=['file', 'shelf_id', 'planogram_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thousand-firewall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "['C1_P01_N1_S2_1.JPG', 'C1_P01_N1_S2_2.JPG', 'C1_P01_N1_S3_1.JPG', 'C1_P01_N1_S3_2.JPG', 'C1_P01_N1_S5_1.JPG']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>shelf_id</th>\n",
       "      <th>planogram_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_P01_N1_S2_2.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1_P01_N1_S3_1.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1_P01_N1_S3_2.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S3_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1_P01_N1_S5_1.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S5_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file shelf_id planogram_id\n",
       "0  C1_P01_N1_S2_1.JPG   C1_P01      N1_S2_1\n",
       "1  C1_P01_N1_S2_2.JPG   C1_P01      N1_S2_2\n",
       "2  C1_P01_N1_S3_1.JPG   C1_P01      N1_S3_1\n",
       "3  C1_P01_N1_S3_2.JPG   C1_P01      N1_S3_2\n",
       "4  C1_P01_N1_S5_1.JPG   C1_P01      N1_S5_1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(jpg_files))\n",
    "print(jpg_files[:5])\n",
    "photos_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excited-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.DataFrame([[f[:18], f[:6], f[7:14], i, *map(int, f[19:-4].split('_'))]\n",
    "                           for i in range(11)\n",
    "                           for f in os.listdir(f'{product_images}{i}') if f.endswith('png')],\n",
    "                          columns = ['file', 'shelf_id', 'planogram_id', 'category', 'xmin', 'ymin', 'w', 'h'])\n",
    "\n",
    "# convert from width, height to xmax, ymax\n",
    "\n",
    "products_df['xmax'] = products_df['xmin'] + products_df['w']\n",
    "products_df['ymax'] = products_df['ymin'] + products_df['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "designing-authorization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13184, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>shelf_id</th>\n",
       "      <th>planogram_id</th>\n",
       "      <th>category</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S2_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1008</td>\n",
       "      <td>1552</td>\n",
       "      <td>252</td>\n",
       "      <td>376</td>\n",
       "      <td>1260</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S2_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1028</td>\n",
       "      <td>928</td>\n",
       "      <td>252</td>\n",
       "      <td>376</td>\n",
       "      <td>1280</td>\n",
       "      <td>1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S2_1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>872</td>\n",
       "      <td>244</td>\n",
       "      <td>392</td>\n",
       "      <td>268</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S2_1</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>1568</td>\n",
       "      <td>252</td>\n",
       "      <td>376</td>\n",
       "      <td>532</td>\n",
       "      <td>1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>C1_P01</td>\n",
       "      <td>N1_S2_1</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>872</td>\n",
       "      <td>252</td>\n",
       "      <td>376</td>\n",
       "      <td>544</td>\n",
       "      <td>1248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file shelf_id planogram_id  category  xmin  ymin    w    h  \\\n",
       "0  C1_P01_N1_S2_1.JPG   C1_P01      N1_S2_1         0  1008  1552  252  376   \n",
       "1  C1_P01_N1_S2_1.JPG   C1_P01      N1_S2_1         0  1028   928  252  376   \n",
       "2  C1_P01_N1_S2_1.JPG   C1_P01      N1_S2_1         0    24   872  244  392   \n",
       "3  C1_P01_N1_S2_1.JPG   C1_P01      N1_S2_1         0   280  1568  252  376   \n",
       "4  C1_P01_N1_S2_1.JPG   C1_P01      N1_S2_1         0   292   872  252  376   \n",
       "\n",
       "   xmax  ymax  \n",
       "0  1260  1928  \n",
       "1  1280  1304  \n",
       "2   268  1264  \n",
       "3   532  1944  \n",
       "4   544  1248  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(products_df.shape)\n",
    "(products_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-sudan",
   "metadata": {},
   "source": [
    "# converting in pascal VOC format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-ancient",
   "metadata": {},
   "source": [
    "#### Done in Create Annotation file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-surgery",
   "metadata": {},
   "source": [
    "# Train with yolov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "democratic-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "provincial-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "concerned-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor boxes for training images and annotation...\n",
      "Average IOU for 9 anchors: 0.71\n",
      "Anchor Boxes generated.\n",
      "Detection configuration saved in  C:\\Users\\Nikhil\\Desktop\\Hackathon\\Intelligent-Conuter-Share-Analyzer\\ML Models\\GroceryDataset\\production\\json\\detection_config.json\n",
      "Evaluating over 109 samples taken from C:\\Users\\Nikhil\\Desktop\\Hackathon\\Intelligent-Conuter-Share-Analyzer\\ML Models\\GroceryDataset\\production\\validation\n",
      "Training over 245 samples  given at C:\\Users\\Nikhil\\Desktop\\Hackathon\\Intelligent-Conuter-Share-Analyzer\\ML Models\\GroceryDataset\\production\\train\n",
      "Training on: \t['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Training with Batch Size:  2\n",
      "Number of Training Samples:  245\n",
      "Number of Validation Samples:  109\n",
      "Number of Experiments:  10\n",
      "Training with transfer learning from pretrained Model\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/10\n",
      " 10/984 [..............................] - ETA: 12:02 - loss: 138.6395 - yolo_layer_3_loss: 13.5365 - yolo_layer_4_loss: 29.0519 - yolo_layer_5_loss: 84.4744"
     ]
    }
   ],
   "source": [
    "execution_path = os.getcwd()\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=os.path.join(execution_path ,\"GroceryDataset\\production\"))\n",
    "trainer.setTrainConfig(object_names_array=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"], batch_size=2, num_experiments=10, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
